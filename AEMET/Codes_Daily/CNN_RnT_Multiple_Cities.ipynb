{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "''' RNN Bidireccional en Keras '''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "import pandas as pd  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats.stats import pearsonr\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "import matplotlib.dates as mdates\n",
    "from copy import copy\n",
    "from utils.NNutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnRnA = np.loadtxt('../../mdnRnA.txt', delimiter=',')\n",
    "startday = pd.datetime(2013, 7, 1)\n",
    "dates = pd.date_range(startday, periods=len(mdnRnA), freq='W')\n",
    "## Weather:\n",
    "list_cities = ['BCN', 'NVR', 'HSC', 'ZGZ']\n",
    "weekly = loadallDF(list_cities, mdnRnA)\n",
    "BCN_arima = weekly['BCN_arima']\n",
    "NVR_arima = weekly['NVR_arima']\n",
    "HSC_arima = weekly['HSC_arima']\n",
    "ZGZ_arima = weekly['ZGZ_arima']\n",
    "DF_list = [BCN_arima, NVR_arima, ZGZ_arima, HSC_arima]\n",
    "arr_str = ['BCN', 'PMP', 'ZGZ', 'HSC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_scaled = scaleallDF(DF_list, arr_str)\n",
    "BCN_scaled = weekly_scaled['BCN']\n",
    "PMP_scaled = weekly_scaled['PMP']\n",
    "HSC_scaled = weekly_scaled['HSC']\n",
    "ZGZ_scaled = weekly_scaled['ZGZ']\n",
    "DFscaled_list = [BCN_scaled, PMP_scaled, ZGZ_scaled, HSC_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 4\n",
    "neuron = [64, 32]\n",
    "test_size=int(0.3 * len(mdnRnA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCN_PMP_scaled = Join_DF_RnT(BCN_scaled, PMP_scaled)\n",
    "BCN_HSC_scaled = Join_DF_RnT(BCN_scaled, HSC_scaled)\n",
    "BCN_ZGZ_scaled = Join_DF_RnT(BCN_scaled, ZGZ_scaled)\n",
    "PMP_HSC_scaled = Join_DF_RnT(PMP_scaled, HSC_scaled)\n",
    "PMP_ZGZ_scaled = Join_DF_RnT(PMP_scaled, ZGZ_scaled)\n",
    "HSC_ZGZ_scaled = Join_DF_RnT(HSC_scaled, ZGZ_scaled)\n",
    "DFscaled_list_couples = [BCN_PMP_scaled, BCN_HSC_scaled, BCN_ZGZ_scaled, PMP_HSC_scaled, PMP_ZGZ_scaled, HSC_ZGZ_scaled]\n",
    "arr_str_couples = ['BCN_PMP', 'BCN_HSC', 'BCN_ZGZ', 'PMP_HSC', 'PMP_ZGZ', 'HSC_ZGZ'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rn + Temperature\n",
    "Xt = data_toCNN_format(DFscaled_list_couples, arr_str_couples, ['tmed', 'tmed1','mdnRnA'], sample_size)\n",
    "Xt_BCN_PMP = Xt['BCN_PMP']\n",
    "Xt_BCN_HSC = Xt['BCN_HSC']\n",
    "Xt_BCN_ZGZ = Xt['BCN_ZGZ']\n",
    "Xt_PMP_HSC = Xt['PMP_HSC']\n",
    "Xt_PMP_ZGZ = Xt['PMP_ZGZ']\n",
    "Xt_HSC_ZGZ = Xt['HSC_ZGZ']\n",
    "Xtrain_BCN_PMP, Xtest_BCN_PMP = train_test_split(Xt_BCN_PMP, test_size)\n",
    "Xtrain_BCN_HSC, Xtest_BCN_HSC = train_test_split(Xt_BCN_HSC, test_size)\n",
    "Xtrain_BCN_ZGZ, Xtest_BCN_ZGZ = train_test_split(Xt_BCN_ZGZ, test_size)\n",
    "Y = mdnRnA[sample_size:]\n",
    "Ytrain, Ytest = Y[:-test_size], Y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict\n",
    "history, pred, acc_train, acc_test = NN(neuron, nep=30, X_train=Xtrain_BCN_PMP, Y_train=Ytrain, X_test=Xtest_BCN_PMP,\n",
    "                                        Y_test=Ytest, sample_size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testScoreECM = mean_squared_error(Ytest, pred)\n",
    "print('ECM: %.4f' % (testScoreECM))\n",
    "testScoreEAM = mean_absolute_error(Ytest, pred)\n",
    "print('EAM: %.4f' % (testScoreEAM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1,figsize=(8,6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss', fontsize=14)\n",
    "plt.xlabel('epoch', fontsize=14)\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('./CNN_Loss_RnT_PMP_{}_{}.png'.format(neuron[0], neuron[1]))\n",
    "np.savetxt('CNN_Loss_RnT_PMP_{}_{}_v2.txt'.format(neuron[0], neuron[1]), (history.history['loss'], history.history['val_loss']), delimiter=',')\n",
    "\n",
    "## Plot2\n",
    "startdaypred = pd.datetime(2013, 7, 1) + 7*pd.Timedelta( len(mdnRnA)-len(pred), unit='D')\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1,figsize=(10,4))\n",
    "xaxis = ax.get_xaxis()\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "ax.plot(pd.date_range(startday, periods=len(mdnRnA), freq='W'), mdnRnA, 'k', alpha=0.7) \n",
    "ax.plot(pd.date_range(startdaypred, periods=len(pred), freq='W'), pred, linewidth=2, linestyle='-',color='crimson')\n",
    "plt.xlabel('Dates', fontsize=16)\n",
    "plt.ylabel(r'$^{222}Rn\\ (Bq/m^3)$', fontsize=16)\n",
    "ax.legend(['Data', 'CNN(Rn + T)'], loc='upper left')\n",
    "plt.ylim([30, 140])\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "axins = zoomed_inset_axes(ax, 1.7, loc='lower left', bbox_to_anchor=(643,140))\n",
    "axins.xaxis.set_major_locator(mdates.YearLocator())\n",
    "axins.xaxis.set_minor_locator(mdates.MonthLocator())\n",
    "axins.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "axins.plot(pd.date_range(startday, periods=len(mdnRnA), freq='W'), mdnRnA, 'k', alpha=0.7) \n",
    "axins.plot(pd.date_range(startdaypred, periods=len(pred), freq='W'), pred, linewidth=2, linestyle='-',color='crimson')\n",
    "axins.set_xlim('2017-10-05', '2019-07-21')\n",
    "axins.set_ylim(50, 110)\n",
    "plt.xticks(visible=True)\n",
    "plt.yticks(visible=False)\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "plt.suptitle('Weekly Fitting at LSC - Hall A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
